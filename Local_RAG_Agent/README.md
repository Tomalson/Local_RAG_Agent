# Local RAG Agent ğŸ¤–

**Inteligencja AI** - System Retrieval-Augmented Generation z lokalnych dokumentÃ³w.

## ğŸ“‹ Opis

Profesjonalny agent RAG wykorzystujÄ…cy:
- **Ollama** - Lokalne modele AI (Llama 3)
- **LangChain** - Framework do aplikacji LLM
- **ChromaDB** - Baza wektorowa
- **PyPDF** - Przetwarzanie dokumentÃ³w

## ğŸ› ï¸ Instalacja

### 1. Zainstaluj Ollama

```bash
# Pobierz ze strony: https://ollama.ai
# NastÄ™pnie pobierz model:
ollama pull llama3
```

### 2. Zainstaluj zaleÅ¼noÅ›ci Python

```bash
pip install -r requirements.txt
```

## ğŸš€ UÅ¼ycie

### Krok 1: Dodaj dokumenty

UmieÅ›Ä‡ pliki w folderze `docs/`:
- **PDF** - dokumenty PDF
- **Markdown** - pliki .md (np. z Data Grinder)

### Krok 2: PrzetwÃ³rz dokumenty

```bash
python ingest.py
```

**Co robi ingest.py:**
- Wczytuje PDF-y i MD z `docs/`
- Dzieli na fragmenty (1000 znakÃ³w)
- Tworzy embeddingi (Llama 3)
- Zapisuje w ChromaDB

### Krok 3: Zadawaj pytania

```bash
python main.py
```

**Interfejs CLI:**
- Wpisz pytanie â†’ Enter
- `stats` - statystyki bazy
- `exit` - wyjÅ›cie

## ğŸ“ Struktura

```
Local_RAG_Agent/
â”œâ”€â”€ config.py              # Konfiguracja systemu
â”œâ”€â”€ ingest.py             # Ingestia docs â†’ ChromaDB
â”œâ”€â”€ rag_service.py        # Logika RAG
â”œâ”€â”€ main.py               # Interfejs CLI
â”œâ”€â”€ requirements.txt      # ZaleÅ¼noÅ›ci
â”‚
â”œâ”€â”€ docs/                 # ğŸ“‚ Dokumenty (input)
â”‚   â”œâ”€â”€ *.pdf            # Pliki PDF
â”‚   â””â”€â”€ *.md             # Pliki Markdown
â”‚
â””â”€â”€ chroma_db/           # Baza wektorowa (output)
```

## ğŸ“¥ Importowanie danych z Data Grinder

### Automatyczne kopiowanie

```bash
# Z folderu Data_Grinder
Copy-Item "output\*.md" -Destination "..\Local_RAG_Agent\docs\"

# NastÄ™pnie przetwÃ³rz
cd ..\Local_RAG_Agent
python ingest.py
```

### Workflow

```
Data_Grinder/output/*.md  
         â†“
Local_RAG_Agent/docs/*.md
         â†“
python ingest.py
         â†“
chroma_db/ (baza wektorowa)
         â†“
python main.py (zadawaj pytania)
```

## âš™ï¸ Konfiguracja

Edytuj [config.py](config.py):

### Model
- `LLM_MODEL` - model Ollama (llama3)
- `EMBEDDING_MODEL` - model embeddingÃ³w (llama3)

### Parametry LLM
- `LLM_TEMPERATURE` - losowoÅ›Ä‡ (0.1)
- `LLM_MAX_TOKENS` - maks. dÅ‚ugoÅ›Ä‡ odpowiedzi (2048)

### Retrieval
- `RETRIEVER_K` - liczba fragmentÃ³w (4)
- `RETRIEVER_SEARCH_TYPE` - typ wyszukiwania (similarity)

### Chunking
- `CHUNK_SIZE` - rozmiar chunka (1000)
- `CHUNK_OVERLAP` - overlap (200)

## ğŸ¯ Prompt systemowy

RAG uÅ¼ywa **rygorystycznego promptu** zapobiegajÄ…cego halucynacjom:

âœ… Odpowiada TYLKO na podstawie kontekstu  
âœ… Nie uÅ¼ywa wiedzy ogÃ³lnej  
âœ… Przyznaje siÄ™ gdy nie ma informacji  
âœ… Cytuje ÅºrÃ³dÅ‚a  

## ğŸ”§ RozwiÄ…zywanie problemÃ³w

### Ollama nie odpowiada

```bash
# SprawdÅº czy dziaÅ‚a
# Local RAG Agent (bez scrapera)

Pytaj wÅ‚asne dokumenty lokalnie przez Ollama.

## Szybki start

```bash
cd Local_RAG_Agent
..\.venv\Scripts\python.exe -m pip install -r requirements.txt
ollama pull llama3
ollama pull nomic-embed-text

# Dla Markdown
..\.venv\Scripts\python.exe ingest_md.py

# Dla PDF
..\.venv\Scripts\python.exe ingest.py

..\.venv\Scripts\python.exe main.py
```

## Konfiguracja

Plik `config.py`:
- `LLM_MODEL` - model generujÄ…cy (domyÅ›lnie llama3)
- `EMBEDDING_MODEL` - embeddingi (domyÅ›lnie nomic-embed-text)
- `RETRIEVER_K` - liczba fragmentÃ³w kontekstu
- `LLM_TEMPERATURE` - temperatura LLM

## Struktura

```
Local_RAG_Agent/
â”œâ”€â”€ docs/          # tu wrzucasz pliki .md / .pdf
â”œâ”€â”€ chroma_db/     # baza wektorowa
â”œâ”€â”€ ingest_md.py   # ingest markdown
â”œâ”€â”€ ingest.py      # ingest pdf
â”œâ”€â”€ main.py        # interfejs Q&A
â””â”€â”€ config.py
```
- "Jak skonfigurowaÄ‡ system?"
- "Jakie sÄ… wymagania systemowe?"
- "Opisz proces instalacji"

### Knowledge base ze stron WWW

```bash
# 1. UÅ¼yj Data Grinder do scrapowania
cd ..\Data_Grinder
python orchestrator.py full https://docs.example.com

# 2. Skopiuj do docs/
Copy-Item "output\*.md" -Destination "..\Local_RAG_Agent\docs\"

# 3. WrÃ³Ä‡ do RAG Agent
cd ..\Local_RAG_Agent
python ingest.py

# 4. Zadawaj pytania
python main.py
```

## ğŸš€ Zaawansowane

### Dodawanie nowych dokumentÃ³w

```bash
# 1. Dodaj nowe pliki do docs/
# 2. UsuÅ„ starÄ… bazÄ™
Remove-Item -Recurse -Force chroma_db

# 3. Przebuduj
python ingest.py
```

### Zmiana modelu

```bash
# Pobierz inny model
ollama pull mistral

# ZmieÅ„ w config.py
LLM_MODEL = "mistral"
```

### Optymalizacja retrieval

```python
# W config.py
RETRIEVER_K = 6  # WiÄ™cej fragmentÃ³w
CHUNK_SIZE = 500  # Mniejsze chunki
CHUNK_OVERLAP = 100
```

## ğŸ“ Format dokumentÃ³w

### Wspierane:
- âœ… PDF (przez PyPDF)
- âœ… Markdown (natywnie)
- âœ… TXT (jako Markdown)

### Rekomendacje:
- PDF: dokumentacja, raporty
- Markdown: artykuÅ‚y, documentation (z Data Grinder)

---

**ğŸ”¥ Agent gotowy do pracy z TwojÄ… bazÄ… wiedzy!**

Pytania? SprawdÅº [config.py](config.py)
